{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2bf9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 00 - Web Scraping & Ingestion\n",
    "# This notebook collects football match data from Transfermarkt and stores it in Delta format for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "# Import all required libraries for web scraping, data handling, and Spark session.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ccadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Spark Session Initialization\n",
    "# Start or get the current Spark session for distributed data processing.\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058cc94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration\n",
    "# Define leagues, scraping parameters, and output paths.\n",
    "LEAGUES = {\n",
    "    'Premier League': {'code': 'GB1', 'url_slug': 'premier-league', 'div_output': 'E0'},\n",
    "    'Championship': {'code': 'GB2', 'url_slug': 'championship', 'div_output': 'E1'},\n",
    "    'Bundesliga': {'code': 'L1', 'url_slug': 'bundesliga', 'div_output': 'D1'},\n",
    "    '2. Bundesliga': {'code': 'L2', 'url_slug': '2-bundesliga', 'div_output': 'D2'},\n",
    "    'Ligue 1': {'code': 'FR1', 'url_slug': 'ligue-1', 'div_output': 'F1'},\n",
    "    'Ligue 2': {'code': 'FR2', 'url_slug': 'ligue-2', 'div_output': 'F2'}\n",
    "}\n",
    "BASE_URL = \"https://www.transfermarkt.com\"\n",
    "START_SEASON = 1993\n",
    "END_SEASON = 2024\n",
    "RAW_BASE_PATH = \"/Volumes/football_matches_catalog/raw/raw_files\"\n",
    "USER_AGENTS = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Helper Functions\n",
    "# Utility functions for HTTP headers and date normalization.\n",
    "def get_headers():\n",
    "    \"\"\"Randomize headers for requests.\"\"\"\n",
    "    return {\n",
    "        'User-Agent': random.choice(USER_AGENTS),\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Referer': 'https://www.google.com/'\n",
    "    }\n",
    "\n",
    "def normalize_date(date_str, season_year):\n",
    "    \"\"\"Normalize date string to dd/mm/yyyy or dd.mm.yyyy format.\"\"\"\n",
    "    if not date_str or date_str == \"Unknown\":\n",
    "        return date_str\n",
    "    try:\n",
    "        if \"/\" in date_str:\n",
    "            sep = \"/\"\n",
    "        elif \".\" in date_str:\n",
    "            sep = \".\"\n",
    "        else:\n",
    "            return date_str\n",
    "        parts = date_str.split(sep)\n",
    "        if len(parts) != 3:\n",
    "            return date_str\n",
    "        day, month, year = parts\n",
    "        if len(year) == 2:\n",
    "            year_int = int(year)\n",
    "            month_int = int(month)\n",
    "            if month_int >= 8:\n",
    "                full_year = season_year\n",
    "            else:\n",
    "                full_year = season_year + 1\n",
    "            if full_year % 100 == year_int:\n",
    "                year = str(full_year)\n",
    "            else:\n",
    "                if year_int < 50:\n",
    "                    year = \"20\" + year\n",
    "                else:\n",
    "                    year = \"19\" + year\n",
    "        return f\"{day}{sep}{month}{sep}{year}\"\n",
    "    except Exception:\n",
    "        return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b. Scraping Function\n",
    "# Scrape all matches for a given league and season from Transfermarkt.\n",
    "def scrape_season(league_name, league_info, season_year):\n",
    "    \"\"\"Scrape all matches for a league and season.\"\"\"\n",
    "    code = league_info['code']\n",
    "    slug = league_info['url_slug']\n",
    "    div_output = league_info['div_output']\n",
    "    url = f\"{BASE_URL}/{slug}/gesamtspielplan/wettbewerb/{code}/saison_id/{season_year}\"\n",
    "    print(f\"Scraping {league_name} {season_year}-{season_year+1} from {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url, headers=get_headers(), timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch {url}: {e}\")\n",
    "        return []\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    matches = []\n",
    "    if soup.title and not any(k in soup.title.text.lower() for k in [\"fixtures\", \"schedule\", \"spielplan\"]):\n",
    "        print(f\"Warning: Page title '{soup.title.text}' might indicate issues.\")\n",
    "    report_links = soup.find_all('a', href=lambda x: x and '/spielbericht/' in x)\n",
    "    seen_matches = set()\n",
    "    current_date = \"Unknown\"\n",
    "    for link in report_links:\n",
    "        try:\n",
    "            match_url_part = link['href']\n",
    "            match_id = match_url_part.split('/')[-1]\n",
    "            if match_id in seen_matches:\n",
    "                continue\n",
    "            seen_matches.add(match_id)\n",
    "            row = link.find_parent('tr')\n",
    "            if not row:\n",
    "                continue\n",
    "            cells = row.find_all('td')\n",
    "            team_links = row.find_all('a', href=lambda x: x and '/verein/' in x)\n",
    "            teams = [t.get_text(strip=True) for t in team_links if t.get_text(strip=True)]\n",
    "            if len(teams) < 2:\n",
    "                imgs = row.find_all('img', alt=True)\n",
    "                teams_from_imgs = [img['alt'] for img in imgs]\n",
    "                if len(teams_from_imgs) >= 2:\n",
    "                    teams = teams_from_imgs[:2]\n",
    "            if len(teams) < 2:\n",
    "                continue\n",
    "            home_team, away_team = teams[0], teams[1]\n",
    "            result_text = link.get_text(strip=True)\n",
    "            if \":\" not in result_text:\n",
    "                continue\n",
    "            fthg, ftag = result_text.split(':')\n",
    "            found_date_in_row = False\n",
    "            raw_date_str = \"\"\n",
    "            for cell in cells[:2]:\n",
    "                txt = cell.get_text(separator=\" \", strip=True)\n",
    "                if any(c.isdigit() for c in txt) and len(txt) > 5 and (\"/\" in txt or \".\" in txt):\n",
    "                    raw_date_str = txt\n",
    "                    found_date_in_row = True\n",
    "                    break\n",
    "            if found_date_in_row:\n",
    "                date_candidate = raw_date_str\n",
    "                if \" \" in date_candidate:\n",
    "                    parts = date_candidate.split(\" \")\n",
    "                    for p in parts:\n",
    "                        if (\"/\" in p or \".\" in p) and any(c.isdigit() for c in p):\n",
    "                            date_candidate = p\n",
    "                            break\n",
    "                current_date = date_candidate\n",
    "            final_date_str = normalize_date(current_date, season_year)\n",
    "            try:\n",
    "                hg = int(fthg)\n",
    "                ag = int(ftag)\n",
    "                if hg > ag:\n",
    "                    ftr = 'H'\n",
    "                elif ag > hg:\n",
    "                    ftr = 'A'\n",
    "                else:\n",
    "                    ftr = 'D'\n",
    "            except Exception:\n",
    "                ftr = 'NA'\n",
    "            matches.append({\n",
    "                'Match_ID': match_id,\n",
    "                'Div': div_output,\n",
    "                'Season': season_year,\n",
    "                'Date': final_date_str,\n",
    "                'HomeTeam': home_team,\n",
    "                'AwayTeam': away_team,\n",
    "                'FTHG': fthg,\n",
    "                'FTAG': ftag,\n",
    "                'FTR': ftr\n",
    "            })\n",
    "        except Exception:\n",
    "            continue\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Main Scraping Loop\n",
    "# Loop through all seasons and leagues, scrape data, and save as Delta files.\n",
    "all_seasons = list(range(START_SEASON, END_SEASON + 1))\n",
    "for season in all_seasons:\n",
    "    all_matches = []\n",
    "    for league_name, league_info in LEAGUES.items():\n",
    "        matches = scrape_season(league_name, league_info, season)\n",
    "        if matches:\n",
    "            all_matches.extend(matches)\n",
    "        time.sleep(random.uniform(1, 3))  # Polite delay\n",
    "    if all_matches:\n",
    "        pdf = pd.DataFrame(all_matches)\n",
    "        sdf = spark.createDataFrame(pdf)\n",
    "        output_path = f\"{RAW_BASE_PATH}/season={season}\"\n",
    "        print(f\"Writing season {season} to {output_path} as Delta...\")\n",
    "        sdf.write.format(\"delta\").mode(\"overwrite\").save(output_path)\n",
    "    else:\n",
    "        print(f\"No matches found for season {season}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
